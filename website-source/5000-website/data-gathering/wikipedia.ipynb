{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](wiki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since wikipedia contains a plethora of information about many different topics, it was an ideal source for gathering comprehensive text data regarding electric vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the essential python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import nltk\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/isfarbaset/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/isfarbaset/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/isfarbaset/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/isfarbaset/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters for the text processing task and intializing the tools for NLP tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS \n",
    "label_list=['electric vehicle', 'gasoline-powered']\n",
    "max_num_pages=25\n",
    "sentence_per_chunk=5\n",
    "min_sentence_length=20\n",
    "\n",
    "# GET STOPWORDS\n",
    "# from nltk.corpus import stopwords\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# INITALIZE STEMMER+LEMITZIZER+SIA\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes a string input and filters out any unwanted characterers and performs tasks such as lemmatization to output a more readable version of the raw, unprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "\t# #FILTER OUT UNWANTED CHAR\n",
    "\tnew_text=\"\"\n",
    "\t# keep=string.printable\n",
    "\tkeep=\" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "\tfor character in text:\n",
    "\t\tif character.lower() in keep:\n",
    "\t\t\tnew_text+=character.lower()\n",
    "\t\telse: \n",
    "\t\t\tnew_text+=\" \"\n",
    "\ttext=new_text\n",
    "\t# print(text)\n",
    "\n",
    "\t# #FILTER OUT UNWANTED WORDS\n",
    "\tnew_text=\"\"\n",
    "\tfor word in nltk.tokenize.word_tokenize(text):\n",
    "\t\tif word not in nltk.corpus.stopwords.words('english'):\n",
    "\t\t\t#lemmatize \n",
    "\t\t\ttmp=lemmatizer.lemmatize(word)\n",
    "\t\t\t# tmp=stemmer.stem(tmp)\n",
    "\n",
    "\t\t\t# update word if there is a change\n",
    "\t\t\t# if(tmp!=word): print(tmp,word)\n",
    "\t\t\t\n",
    "\t\t\tword=tmp\n",
    "\t\t\tif len(word)>1:\n",
    "\t\t\t\tif word in [\".\",\",\",\"!\",\"?\",\":\",\";\"]:\n",
    "\t\t\t\t\t#remove the last space\n",
    "\t\t\t\t\tnew_text=new_text[0:-1]+word+\" \"\n",
    "\t\t\t\telse: #add a space\n",
    "\t\t\t\t\tnew_text+=word.lower()+\" \"\n",
    "\ttext=new_text.strip()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code snippet, Wikipedia is scraped for text data contaning the specific keywords and sentiments are set to the tedxt chunks to facilitate conducting sentiments analysis later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages for label = electric vehicle : ['Electric vehicle', 'History of the electric vehicle', 'Battery electric vehicle', 'Electric vehicle battery', 'Hybrid electric vehicle', 'Electric car use by country', 'Plug-in electric vehicle', 'List of production battery electric vehicles', 'Neighborhood Electric Vehicle', 'Hybrid vehicle drivetrain', 'Aptera (solar electric vehicle)', 'Electric car', 'Capacitor electric vehicle', 'Electric vehicle conversion', 'Hybrid vehicle', 'Plug-in hybrid', 'Charging station', 'Citroën Ami (electric vehicle)', 'Grumman LLV', 'Fuel cell vehicle', 'London Electric Vehicle Company', 'Electric vehicle industry in China', 'Electric Vehicle Company', 'Tesla, Inc.', 'Plug-in electric vehicles in China']\n",
      "\t Electric vehicle\n",
      "\t History of the electric vehicle\n",
      "\t Battery electric vehicle\n",
      "\t Electric vehicle battery\n",
      "\t Hybrid electric vehicle\n",
      "\t Electric car use by country\n",
      "\t Plug-in electric vehicle\n",
      "\t List of production battery electric vehicles\n",
      "\t Neighborhood Electric Vehicle\n",
      "\t Hybrid vehicle drivetrain\n",
      "\t Aptera (solar electric vehicle)\n",
      "\t Electric car\n",
      "\t Capacitor electric vehicle\n",
      "\t Electric vehicle conversion\n",
      "\t Hybrid vehicle\n",
      "\t Plug-in hybrid\n",
      "\t Charging station\n",
      "WARNING: SOMETHING WENT WRONG: Charging station\n",
      "\t Citroën Ami (electric vehicle)\n",
      "\t Grumman LLV\n",
      "\t Fuel cell vehicle\n",
      "WARNING: SOMETHING WENT WRONG: Fuel cell vehicle\n",
      "\t London Electric Vehicle Company\n",
      "\t Electric vehicle industry in China\n",
      "\t Electric Vehicle Company\n",
      "\t Tesla, Inc.\n",
      "\t Plug-in electric vehicles in China\n",
      "Pages for label = gasoline-powered : ['Petrol engine', 'Tractor', 'Charles Duryea', 'Gasoline', 'History of the automobile', 'Waterloo Gasoline Engine Company', 'Chainsaw', 'Lawn mower', 'Catalytic converter', 'ZF S6-37 transmission', 'Mercedes-Benz MB517 engine', 'Ford Duratec engine', 'Motorized bicycle', 'Chevrolet small-block engine', 'Mazda MZR engine', 'Mercedes-Benz MB507 engine', 'Houseboat', 'Hydrogen internal combustion engine vehicle', 'Trolling motor', 'Radio-controlled car', 'Maxus G90', 'Natural gas vehicle', 'Two-stroke oil', 'String trimmer', 'Hydrogen vehicle']\n",
      "\t Petrol engine\n",
      "\t Tractor\n",
      "WARNING: SOMETHING WENT WRONG: Tractor\n",
      "\t Charles Duryea\n",
      "\t Gasoline\n",
      "\t History of the automobile\n",
      "\t Waterloo Gasoline Engine Company\n",
      "\t Chainsaw\n",
      "\t Lawn mower\n",
      "\t Catalytic converter\n",
      "WARNING: SOMETHING WENT WRONG: Catalytic converter\n",
      "\t ZF S6-37 transmission\n",
      "\t Mercedes-Benz MB517 engine\n",
      "\t Ford Duratec engine\n",
      "\t Motorized bicycle\n",
      "\t Chevrolet small-block engine\n",
      "\t Mazda MZR engine\n",
      "\t Mercedes-Benz MB507 engine\n",
      "\t Houseboat\n",
      "\t Hydrogen internal combustion engine vehicle\n",
      "\t Trolling motor\n",
      "\t Radio-controlled car\n",
      "\t Maxus G90\n",
      "\t Natural gas vehicle\n",
      "\t Two-stroke oil\n",
      "\t String trimmer\n",
      "\t Hydrogen vehicle\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZE \n",
    "corpus=[]  # list of strings (input variables X)\n",
    "targets=[] # list of targets (labels or response variables Y)\n",
    "\n",
    "#--------------------------\n",
    "# LOOP OVER TOPICS \n",
    "#--------------------------\n",
    "for label in label_list:\n",
    "\n",
    "\t#SEARCH FOR RELEVANT PAGES \n",
    "\ttitles=wikipedia.search(label,results=max_num_pages)\n",
    "\tprint(\"Pages for label =\",label,\":\",titles)\n",
    "\n",
    "\t#LOOP OVER WIKI-PAGES\n",
    "\tfor title in titles:\n",
    "\t\ttry:\n",
    "\t\t\tprint(\"\t\",title)\n",
    "\t\t\twiki_page = wikipedia.page(title, auto_suggest=True)\n",
    "\n",
    "\t\t\t# LOOP OVER SECTIONS IN ARTICLE AND GET PAGE TEXT\n",
    "\t\t\tfor section in wiki_page.sections:\n",
    "\t\t\t\ttext=wiki_page.section(section); #print(text)\n",
    "\n",
    "\t\t\t\t#BREAK IN TO SENTANCES \n",
    "\t\t\t\tsentences=nltk.tokenize.sent_tokenize(text)\n",
    "\t\t\t\tcounter=0\n",
    "\t\t\t\ttext_chunk=''\n",
    "\n",
    "\t\t\t\t#LOOP OVER SENTENCES \n",
    "\t\t\t\tfor sentence in sentences:\n",
    "\t\t\t\t\tif len(sentence)>min_sentence_length:\n",
    "\t\t\t\t\t\tif(counter%sentence_per_chunk==0 and counter!=0):\n",
    "\t\t\t\t\t\t\t# PROCESS COMPLETED CHUNK \n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# CLEAN STRING\n",
    "\t\t\t\t\t\t\ttext_chunk=clean_string(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t# REMOVE LABEL IF IN STRING (MAKES IT TOO EASY)\n",
    "\t\t\t\t\t\t\ttext_chunk=text_chunk.replace(label,\"\")\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# REMOVE ANY DOUBLE SPACES\n",
    "\t\t\t\t\t\t\ttext_chunk=' '.join(text_chunk.split()).strip()\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE CORPUS \n",
    "\t\t\t\t\t\t\tcorpus.append(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE TARGETS\n",
    "\t\t\t\t\t\t\tscore=sia.polarity_scores(text_chunk)\n",
    "\t\t\t\t\t\t\ttarget=[label,score['compound']]\n",
    "\t\t\t\t\t\t\ttargets.append(target)\n",
    "\n",
    "\t\t\t\t\t\t\t#print(\"TEXT\\n\",text_chunk,target)\n",
    "\n",
    "\t\t\t\t\t\t\t# RESET CHUNK FOR NEXT ITERATION \n",
    "\t\t\t\t\t\t\ttext_chunk=sentence\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ttext_chunk+=sentence\n",
    "\t\t\t\t\t\t#print(\"--------\\n\", sentence)\n",
    "\t\t\t\t\t\tcounter+=1\n",
    "\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"WARNING: SOMETHING WENT WRONG:\", title);  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collected text data is shaped into a dataframe and stored in a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of text chunks =  723\n",
      "number of targets =  723\n",
      "                                                  text             label  \\\n",
      "0    electric motive power started 1827 hungarian p...  electric vehicle   \n",
      "1    first mass produced appeared america early 190...  electric vehicle   \n",
      "2    20th century uk world largest user electric ro...  electric vehicle   \n",
      "3    1900 28 percent car road electric ev popular e...  electric vehicle   \n",
      "4    seldom marketed woman luxury car may stigma am...  electric vehicle   \n",
      "..                                                 ...               ...   \n",
      "718  lifetime hydrogen vehicle emit carbon gasoline...  gasoline-powered   \n",
      "719  convert hydrogen back electricity fuel cell an...  gasoline-powered   \n",
      "720  2019 video real engineering noted notwithstand...  gasoline-powered   \n",
      "721  maybe hydrogen fuel cell car come technology n...  gasoline-powered   \n",
      "722  internal combustion engine based compressed na...  gasoline-powered   \n",
      "\n",
      "     sentiment  \n",
      "0      -0.7506  \n",
      "1       0.9201  \n",
      "2       0.7096  \n",
      "3       0.9169  \n",
      "4       0.9231  \n",
      "..         ...  \n",
      "718     0.9100  \n",
      "719     0.9136  \n",
      "720     0.7964  \n",
      "721     0.9260  \n",
      "722     0.9118  \n",
      "\n",
      "[723 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#SANITY CHECKS AND PRINT TO FILE \n",
    "print(\"number of text chunks = \",len(corpus))\n",
    "print(\"number of targets = \",len(targets))\n",
    "\n",
    "tmp=[]\n",
    "for i in range(0,len(corpus)):\n",
    "    tmp.append([corpus[i],targets[i][0],targets[i][1]])\n",
    "df=pd.DataFrame(tmp)\n",
    "df=df.rename(columns={0: \"text\", 1: \"label\", 2: \"sentiment\"})\n",
    "print(df)\n",
    "df.to_csv('wiki-crawl-results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://drive.google.com/drive/folders/1O62qRfigp1T6bXVOpMg2Z_1CHn8tXh-d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
