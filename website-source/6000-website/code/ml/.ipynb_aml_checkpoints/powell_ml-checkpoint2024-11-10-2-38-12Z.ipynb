{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "RUNNING": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "59",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T23:46:38.5870418Z",
              "session_start_time": "2024-12-09T23:46:38.6693441Z",
              "execution_start_time": "2024-12-09T23:47:53.8528026Z",
              "execution_finish_time": "2024-12-09T23:47:54.2599798Z",
              "parent_msg_id": "3c86087f-cc2f-44ae-8fde-1d2a2dd600ff"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 59, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<pyspark.sql.session.SparkSession at 0x7f30a6289750>",
            "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://vm-1c872059:37155\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.4.3.5.3.20241016.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Azure ML Experiment</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1733788037978
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "\n",
        "subscription_id = '21ff0fc0-dd2c-450d-93b7-96eeb3699b22'\n",
        "resource_group = 'project-group-29'\n",
        "workspace_name = 'project-group-29'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "datastore = Datastore.get(workspace, \"workspaceblobstore\")\n",
        "dataset = Dataset.Tabular.from_parquet_files(path=(datastore, 'states/states_sentiment'))\n",
        "df = dataset.to_spark_dataframe()\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 1,
                  "RUNNING": 0
                },
                "jobs": [
                  {
                    "displayName": "head at /tmp/ipykernel_91382/2394195642.py:12",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 19,
                    "usageDescription": "",
                    "jobId": 0,
                    "name": "head at /tmp/ipykernel_91382/2394195642.py:12",
                    "description": "Job group for statement 7:\nfrom azureml.core import Workspace, Dataset, Datastore\n\nsubscription_id = '21ff0fc0-dd2c-450d-93b7-96eeb3699b22'\nresource_group = 'project-group-29'\nworkspace_name = 'project-group-29'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\ndatastore = Datastore.get(workspace, \"workspaceblobstore\")\ndataset = Dataset.Tabular.from_parquet_files(path=(datastore, 'states/states_sentiment'))\ndf = dataset.to_spark_dataframe()\ndf.head()",
                    "submissionTime": "2024-12-09T23:48:06.664GMT",
                    "completionTime": "2024-12-09T23:48:25.139GMT",
                    "stageIds": [
                      0
                    ],
                    "jobGroup": "7",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "59",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T23:46:45.9915142Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T23:47:54.3948014Z",
              "execution_finish_time": "2024-12-09T23:48:27.2744542Z",
              "parent_msg_id": "3e9bfd74-e5ba-4f63-9936-004801e1c784"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 59, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'infer_column_types': 'False', 'activity': 'to_spark_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_spark_dataframe', 'activityApp': 'TabularDataset'}\n{'infer_column_types': 'False', 'activity': 'to_spark_dataframe', 'activityApp': 'TabularDataset', 'runId': '2b7c5281-0c7f-49e8-9d40-e9b4483b4fd4'}\n{'infer_column_types': 'False', 'activity': 'to_spark_dataframe', 'activityApp': 'TabularDataset', 'runId': '2b7c5281-0c7f-49e8-9d40-e9b4483b4fd4', 'run_id': '2b7c5281-0c7f-49e8-9d40-e9b4483b4fd4'}\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "Row(author='fireweedflowers', text='I live in Colorado these days but I was born and raised in Wyoming and was emphatically a socialist.', controversiality=0, created_utc=1701619261, distinguished=None, edited=None, gilded=0, id='kbtqz1h', parent_id='t3_187jmr5', score=1, subreddit='wyoming', subreddit_id='t5_2r53d', alaska=False, alabama=False, arkansas=False, american samoa=False, arizona=False, california=False, colorado=True, connecticut=False, district of columbia=False, delaware=False, florida=False, georgia=False, guam=False, hawaii=False, iowa=False, idaho=False, illinois=False, indiana=False, kansas=False, kentucky=False, louisiana=False, massachusetts=False, maryland=False, maine=False, michigan=False, minnesota=False, missouri=False, mississippi=False, montana=False, north carolina=False, north dakota=False, nebraska=False, new hampshire=False, new jersey=False, new mexico=False, nevada=False, new york=False, ohio=False, oklahoma=False, oregon=False, pennsylvania=False, puerto rico=False, rhode island=False, south carolina=False, south dakota=False, tennessee=False, texas=False, utah=False, virginia=False, virgin islands=False, vermont=False, washington=False, wisconsin=False, west virginia=False, wyoming=True, sentiment_num=1)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733788070995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.printSchema()\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 1,
                  "RUNNING": 0
                },
                "jobs": [
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 19,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 8:\n#df.printSchema()\ndf.show()",
                    "submissionTime": "2024-12-09T19:39:31.841GMT",
                    "completionTime": "2024-12-09T19:39:47.182GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "8",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "55",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T19:32:05.5088928Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T19:39:30.9520027Z",
              "execution_finish_time": "2024-12-09T19:39:49.7881596Z",
              "parent_msg_id": "4ea49da5-12a5-4901-9a67-f489d9acb217"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 55, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+--------------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+-----+-------------------+------------+------+-------+--------+--------------+-------+----------+--------+-----------+--------------------+--------+-------+-------+-----+------+-----+-----+--------+-------+------+--------+---------+-------------+--------+-----+--------+---------+--------+-----------+-------+--------------+------------+--------+-------------+----------+----------+------+--------+-----+--------+------+------------+-----------+------------+--------------+------------+---------+-----+-----+--------+--------------+-------+----------+---------+-------------+-------+-------------+\n|              author|                text|controversiality|created_utc|distinguished|edited|gilded|     id| parent_id|score|          subreddit|subreddit_id|alaska|alabama|arkansas|american samoa|arizona|california|colorado|connecticut|district of columbia|delaware|florida|georgia| guam|hawaii| iowa|idaho|illinois|indiana|kansas|kentucky|louisiana|massachusetts|maryland|maine|michigan|minnesota|missouri|mississippi|montana|north carolina|north dakota|nebraska|new hampshire|new jersey|new mexico|nevada|new york| ohio|oklahoma|oregon|pennsylvania|puerto rico|rhode island|south carolina|south dakota|tennessee|texas| utah|virginia|virgin islands|vermont|washington|wisconsin|west virginia|wyoming|sentiment_num|\n+--------------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+-----+-------------------+------------+------+-------+--------+--------------+-------+----------+--------+-----------+--------------------+--------+-------+-------+-----+------+-----+-----+--------+-------+------+--------+---------+-------------+--------+-----+--------+---------+--------+-----------+-------+--------------+------------+--------+-------------+----------+----------+------+--------+-----+--------+------+------------+-----------+------------+--------------+------------+---------+-----+-----+--------+--------------+-------+----------+---------+-------------+-------+-------------+\n|     fireweedflowers|I live in Colorad...|               0| 1701619261|         null|  null|     0|kbtqz1h|t3_187jmr5|    1|            wyoming|    t5_2r53d| false|  false|   false|         false|  false|     false|    true|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|   true|            1|\n|               IHB31|If Iowa was 12-1 ...|               0| 1701619262|         null|  null|     0|kbtqz3t|t1_kbtqbur|    2|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false| true|false|   false|  false| false|   false|    false|        false|   false|false|    true|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|      Moonlight12350|On FD participant...|               0| 1701619262|         null|  null|     0|kbtqz49|t3_189lmgf|    1|         sportsbook|    t5_2s3v4| false|   true|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|    true|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|      true|    false|        false|  false|            1|\n|    fuzzypetiolesguy|Wrecked by who? U...|               0| 1701619263|         null|  null|     0|kbtqz6w|t1_kbrzgkq|    1|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|      Suck_Me_Dry666|I think you naile...|               0| 1701619264|         null|  null|     0|kbtqz90|t3_189k238|   -1|          geography|    t5_2qnms| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|   true| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|             crc2993|Man, Iâ€™d honestly...|               0| 1701619264|         null|  null|     0|kbtqzal|t1_kbtqb3v|    1|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|     false|    false|        false|  false|            0|\n|         BurstAgentX|The latter, and i...|               0| 1701619265|         null|  null|     0|kbtqzdm|t1_kbtj7lx|    1|KitchenConfidential|    t5_2sa8b| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|        true|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|       onesneakymofo|You're one of the...|               0| 1701619266|         null|  null|     0|kbtqze2|t1_kbtq2e4|    1|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|     false|    false|        false|  false|            0|\n|Justacouplemoreholes|Don't lose to Tex...|               0| 1701619268|         null|  null|     0|kbtqzmg|t1_kbt963r|  -11|           rolltide|    t5_2sanc| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|         poonjouster|Cardale and the B...|               0| 1701619268|         null|  null|     0|kbtqznf|t1_kbt3xq6|    0|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|    true|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|     true|        false|  false|           -1|\n|     SpartansStandUp|No, Texas is a on...|               0| 1701619269|         null|  null|     0|kbtqzo1|t3_189tmhm|   -2|                CFB|    t5_2qm9d| false|   true|   false|         false|  false|     false|   false|      false|               false|   false|  false|   true|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|    true| false|       false|      false|       false|         false|       false|    false| true|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|         pericles123|it comes down to ...|               0| 1701619269|         null|  null|     0|kbtqzog|t3_189vp4v|    2|                CFB|    t5_2qm9d| false|   true|   false|         false|  false|     false|   false|      false|               false|   false|  false|   true|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false| true|   false|  true|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|              _cdlc_|I was in complete...|               0| 1701619269|         null|  null|     0|kbtqzq4|t3_189ohq3|   27|       greysanatomy|    t5_2t2vo| false|  false|   false|         false|   true|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|     toomuchfrosting|Breaking: NCAA ha...|               0| 1701619270|         null|  null|     0|kbtqzrq|t3_189wh00|    5|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|    true|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|         Smokey19mom|If you like the J...|               0| 1701619270|         null|  null|     0|kbtqztk|t3_189w9we|    2|            bourbon|    t5_2rgos| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|    true|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|          Langland88|I guess that migh...|               0| 1701619271|         null|  null|     0|kbtqzvu|t3_189i18m|    2|          wisconsin|    t5_2qrc2| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|     true|        false|  false|            1|\n|     flaminhotcheeto|They just got luc...|               0| 1701619271|         null|  null|     0|kbtqzwj|t1_kbrpgw1|    0|                CFB|    t5_2qm9d| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false|  true|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|      SamOfTheTetons|This is how it sh...|               1| 1701619273|         null|  null|     0|kbtr01m|t1_kbs64nm|    0|       PardonMyTake|    t5_3d389| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|    true|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|           -1|\n|            LordSahu|If you want a hig...|               0| 1701619273|         null|  null|     0|kbtr02e|t3_189ph2m|    3|       Pathfinder2e|    t5_gkc60| false|  false|   false|         false|  false|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|    true|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n|  Acceptable-CatProf|I am not super fa...|               0| 1701619273|         null|  null|     0|kbtr03i|t3_189n826|    3|SameGrassButGreener|    t5_2u6j8| false|  false|   false|         false|   true|     false|   false|      false|               false|   false|  false|  false|false| false|false|false|   false|  false| false|   false|    false|        false|   false|false|   false|    false|   false|      false|  false|         false|       false|   false|        false|     false|     false| false|   false|false|   false| false|       false|      false|       false|         false|       false|    false|false|false|   false|         false|  false|     false|    false|        false|  false|            1|\n+--------------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+-----+-------------------+------------+------+-------+--------+--------------+-------+----------+--------+-----------+--------------------+--------+-------+-------+-----+------+-----+-----+--------+-------+------+--------+---------+-------------+--------+-----+--------+---------+--------+-----------+-------+--------------+------------+--------+-------------+----------+----------+------+--------+-----+--------+------+------------+-----------+------------+--------------+------------+---------+-----+-----+--------+--------------+-------+----------+---------+-------------+-------+-------------+\nonly showing top 20 rows\n\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733773153868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \n",
        "\"Colorado\", \"Connecticut\", \"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \n",
        "\"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \n",
        "\"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \n",
        "\"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \n",
        "\"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \n",
        "\"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \n",
        "\"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
        "state_names = [x.lower() for x in state_names]\n",
        "\n",
        "state_names.append(\"sentiment_num\")\n",
        "state_names.append(\"rawFeatures\")\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = VectorAssembler(inputCols= state_names, outputCol=\"features\")\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"score\")\n",
        "\n",
        "pipeline_linear = Pipeline(stages=[tokenizer, hashingTF, idf, lr])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 13,
              "statement_ids": [
                13
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "RUNNING": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "55",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T20:16:18.0456034Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T20:16:18.1836454Z",
              "execution_finish_time": "2024-12-09T20:16:18.5202705Z",
              "parent_msg_id": "5b6f7a3d-4268-46d7-8586-18d1e63e443a"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 55, 13, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733775342423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
        "\n",
        "model_linear = pipeline_linear.fit(trainingData)\n",
        "predictions_linear = model_linear.transform(testData)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 15,
              "statement_ids": [
                15
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "RUNNING": 0
                },
                "jobs": [
                  {
                    "displayName": "treeAggregate at Statistics.scala:58",
                    "dataWritten": 2942,
                    "dataRead": 2942,
                    "rowCount": 170,
                    "usageDescription": "",
                    "jobId": 7,
                    "name": "treeAggregate at Statistics.scala:58",
                    "description": "Job group for statement 15:\n(trainingData, testData) = df.randomSplit([0.7, 0.3])\n\nmodel_linear = pipeline_linear.fit(trainingData)\npredictions_linear = model_linear.transform(testData)",
                    "submissionTime": "2024-12-09T20:30:19.913GMT",
                    "completionTime": "2024-12-09T20:42:45.148GMT",
                    "stageIds": [
                      12,
                      13
                    ],
                    "jobGroup": "15",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 10,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 10,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 10,
                    "numActiveStages": 0,
                    "numCompletedStages": 2,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "treeAggregate at WeightedLeastSquares.scala:107",
                    "dataWritten": 20582196,
                    "dataRead": 20582196,
                    "rowCount": 170,
                    "usageDescription": "",
                    "jobId": 6,
                    "name": "treeAggregate at WeightedLeastSquares.scala:107",
                    "description": "Job group for statement 15:\n(trainingData, testData) = df.randomSplit([0.7, 0.3])\n\nmodel_linear = pipeline_linear.fit(trainingData)\npredictions_linear = model_linear.transform(testData)",
                    "submissionTime": "2024-12-09T20:17:22.902GMT",
                    "completionTime": "2024-12-09T20:30:18.750GMT",
                    "stageIds": [
                      10,
                      11
                    ],
                    "jobGroup": "15",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 10,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 10,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 10,
                    "numActiveStages": 0,
                    "numCompletedStages": 2,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "55",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T20:17:21.6586219Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T20:17:21.8045611Z",
              "execution_finish_time": "2024-12-09T20:42:50.1132692Z",
              "parent_msg_id": "130020c9-4d24-4e97-ba8a-5256400e7061"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 55, 15, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733776934195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = 'azureml://datastores/workspaceblobstore/paths'\n",
        "model_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 7,
                  "RUNNING": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at LinearRegression.scala:790",
                    "dataWritten": 10569,
                    "dataRead": 8584,
                    "rowCount": 2,
                    "usageDescription": "",
                    "jobId": 34,
                    "name": "parquet at LinearRegression.scala:790",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:41.141GMT",
                    "completionTime": "2024-12-09T20:54:42.685GMT",
                    "stageIds": [
                      42,
                      43
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 2,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 1,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at LinearRegression.scala:790",
                    "dataWritten": 8584,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 33,
                    "name": "parquet at LinearRegression.scala:790",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:40.789GMT",
                    "completionTime": "2024-12-09T20:54:40.916GMT",
                    "stageIds": [
                      41
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at SparkHadoopWriter.scala:85",
                    "dataWritten": 521,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 32,
                    "name": "runJob at SparkHadoopWriter.scala:85",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:39.889GMT",
                    "completionTime": "2024-12-09T20:54:40.419GMT",
                    "stageIds": [
                      40
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at SparkHadoopWriter.scala:85",
                    "dataWritten": 982,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 31,
                    "name": "runJob at SparkHadoopWriter.scala:85",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:38.873GMT",
                    "completionTime": "2024-12-09T20:54:39.431GMT",
                    "stageIds": [
                      39
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at SparkHadoopWriter.scala:85",
                    "dataWritten": 323,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 30,
                    "name": "runJob at SparkHadoopWriter.scala:85",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:37.573GMT",
                    "completionTime": "2024-12-09T20:54:38.263GMT",
                    "stageIds": [
                      38
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at SparkHadoopWriter.scala:85",
                    "dataWritten": 261,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 29,
                    "name": "runJob at SparkHadoopWriter.scala:85",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:36.466GMT",
                    "completionTime": "2024-12-09T20:54:37.099GMT",
                    "stageIds": [
                      37
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at SparkHadoopWriter.scala:85",
                    "dataWritten": 306,
                    "dataRead": 0,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 28,
                    "name": "runJob at SparkHadoopWriter.scala:85",
                    "description": "Job group for statement 23:\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_linear.write().overwrite().save(f\"{datastore}/models/ml_model_linear_score_prediction\")",
                    "submissionTime": "2024-12-09T20:54:35.145GMT",
                    "completionTime": "2024-12-09T20:54:35.904GMT",
                    "stageIds": [
                      36
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "55",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T20:54:34.4029418Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T20:54:34.5169234Z",
              "execution_finish_time": "2024-12-09T20:54:43.8023342Z",
              "parent_msg_id": "3f5ecc20-462a-4efb-8f0d-4f963b1411a5"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 55, 23, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733777647703
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "PipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \n",
        "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions_linear)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 17,
              "statement_ids": [
                17
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 13,
                  "RUNNING": 0
                },
                "jobs": [
                  {
                    "displayName": "treeAggregate at Statistics.scala:58",
                    "dataWritten": 2942,
                    "dataRead": 2942,
                    "rowCount": 170,
                    "usageDescription": "",
                    "jobId": 27,
                    "name": "treeAggregate at Statistics.scala:58",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:13.456GMT",
                    "completionTime": "2024-12-09T20:50:02.031GMT",
                    "stageIds": [
                      34,
                      35
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 10,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 10,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 10,
                    "numActiveStages": 0,
                    "numCompletedStages": 2,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "head at LinearRegression.scala:845",
                    "dataWritten": 0,
                    "dataRead": 13951,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 26,
                    "name": "head at LinearRegression.scala:845",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:12.504GMT",
                    "completionTime": "2024-12-09T20:43:13.075GMT",
                    "stageIds": [
                      33
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "load at LinearRegression.scala:833",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 25,
                    "name": "load at LinearRegression.scala:833",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:11.126GMT",
                    "completionTime": "2024-12-09T20:43:12.211GMT",
                    "stageIds": [
                      32
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 521,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 24,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:10.676GMT",
                    "completionTime": "2024-12-09T20:43:10.755GMT",
                    "stageIds": [
                      31
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 521,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 23,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:10.506GMT",
                    "completionTime": "2024-12-09T20:43:10.589GMT",
                    "stageIds": [
                      30
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 982,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 22,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:10.286GMT",
                    "completionTime": "2024-12-09T20:43:10.390GMT",
                    "stageIds": [
                      29
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 982,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 21,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:10.080GMT",
                    "completionTime": "2024-12-09T20:43:10.166GMT",
                    "stageIds": [
                      28
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 323,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 20,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:09.903GMT",
                    "completionTime": "2024-12-09T20:43:09.995GMT",
                    "stageIds": [
                      27
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 323,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 19,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:09.711GMT",
                    "completionTime": "2024-12-09T20:43:09.788GMT",
                    "stageIds": [
                      26
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 261,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 18,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:09.514GMT",
                    "completionTime": "2024-12-09T20:43:09.612GMT",
                    "stageIds": [
                      25
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 261,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 17,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:09.262GMT",
                    "completionTime": "2024-12-09T20:43:09.389GMT",
                    "stageIds": [
                      24
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "first at ReadWrite.scala:587",
                    "dataWritten": 0,
                    "dataRead": 306,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "first at ReadWrite.scala:587",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:08.894GMT",
                    "completionTime": "2024-12-09T20:43:09.156GMT",
                    "stageIds": [
                      23
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "runJob at PythonRDD.scala:185",
                    "dataWritten": 0,
                    "dataRead": 306,
                    "rowCount": 1,
                    "usageDescription": "",
                    "jobId": 15,
                    "name": "runJob at PythonRDD.scala:185",
                    "description": "Job group for statement 17:\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nPipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions_linear)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)",
                    "submissionTime": "2024-12-09T20:43:07.166GMT",
                    "completionTime": "2024-12-09T20:43:08.760GMT",
                    "stageIds": [
                      22
                    ],
                    "jobGroup": "17",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "55",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T20:41:23.9420398Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T20:43:06.9317794Z",
              "execution_finish_time": "2024-12-09T20:50:04.9443957Z",
              "parent_msg_id": "674ccf99-2eb4-4b59-bdd7-23c7bc870af9"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 55, 17, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Root Mean Squared Error (RMSE) on test data = 68.5895\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733777368905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.regression import RandomForestRegressor"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "RUNNING": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "59",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T23:46:49.6621331Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T23:48:27.4030203Z",
              "execution_finish_time": "2024-12-09T23:48:28.2303587Z",
              "parent_msg_id": "92e29b41-41f5-409d-a8af-5494c1299625"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 59, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733788071929
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \n",
        "\"Colorado\", \"Connecticut\", \"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \n",
        "\"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \n",
        "\"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \n",
        "\"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \n",
        "\"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \n",
        "\"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \n",
        "\"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
        "state_names = [x.lower() for x in state_names]\n",
        "\n",
        "state_names.append(\"sentiment_num\")\n",
        "state_names.append(\"rawFeatures\")\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = VectorAssembler(inputCols= state_names, outputCol=\"features\")\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol = \"score\")\n",
        "\n",
        "pipeline_forest = Pipeline(stages=[tokenizer, hashingTF, idf, rf])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 9,
              "statement_ids": [
                9
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "RUNNING": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "59",
              "normalized_state": "finished",
              "queued_time": "2024-12-09T23:46:52.5507191Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T23:48:28.3808656Z",
              "execution_finish_time": "2024-12-09T23:48:28.6795768Z",
              "parent_msg_id": "06ff4c5f-5c03-43ab-99ca-d5b4944428f9"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 59, 9, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733788072364
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
        "\n",
        "model_forest = pipeline_forest.fit(trainingData)\n",
        "predictions_forest = model_forest.transform(testData)\n",
        "\n",
        "datastore = 'azureml://datastores/workspaceblobstore/paths'\n",
        "model_forest.write().overwrite().save(f\"{datastore}/models/ml_model_forest_score_prediction\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "09c8ba2d-49fa-498b-9d76-d59b947bd032",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "submitted",
              "livy_statement_state": "running",
              "spark_jobs": {
                "numbers": {
                  "FAILED": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 1,
                  "RUNNING": 1
                },
                "jobs": [
                  {
                    "displayName": "aggregate at DecisionTreeMetadata.scala:125",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 2,
                    "name": "aggregate at DecisionTreeMetadata.scala:125",
                    "description": "Job group for statement 10:\n(trainingData, testData) = df.randomSplit([0.7, 0.3])\n\nmodel_forest = pipeline_forest.fit(trainingData)\npredictions_forest = model_forest.transform(testData)\n\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_forest.write().overwrite().save(f\"{datastore}/models/ml_model_forest_score_prediction\")",
                    "submissionTime": "2024-12-09T23:49:28.878GMT",
                    "stageIds": [
                      2
                    ],
                    "jobGroup": "10",
                    "jobTags": [],
                    "status": "RUNNING",
                    "numTasks": 8,
                    "numActiveTasks": 8,
                    "numCompletedTasks": 0,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 0,
                    "numActiveStages": 1,
                    "numCompletedStages": 0,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "take at DecisionTreeMetadata.scala:119",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 19,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "take at DecisionTreeMetadata.scala:119",
                    "description": "Job group for statement 10:\n(trainingData, testData) = df.randomSplit([0.7, 0.3])\n\nmodel_forest = pipeline_forest.fit(trainingData)\npredictions_forest = model_forest.transform(testData)\n\ndatastore = 'azureml://datastores/workspaceblobstore/paths'\nmodel_forest.write().overwrite().save(f\"{datastore}/models/ml_model_forest_score_prediction\")",
                    "submissionTime": "2024-12-09T23:48:31.684GMT",
                    "completionTime": "2024-12-09T23:49:28.839GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "10",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "59",
              "normalized_state": "running",
              "queued_time": "2024-12-09T23:46:54.7682218Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-09T23:48:28.8065933Z",
              "execution_finish_time": null,
              "parent_msg_id": "87e3e10e-ffc0-4692-a766-118e2191e27b"
            },
            "text/plain": "StatementMeta(09c8ba2d-49fa-498b-9d76-d59b947bd032, 59, 10, Submitted, Running, Running)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733794073295
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \n",
        "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions_forest)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "statement_id": null,
              "statement_ids": null,
              "state": "waiting",
              "livy_statement_state": null,
              "spark_jobs": null,
              "session_id": null,
              "normalized_state": "waiting",
              "queued_time": "2024-12-09T23:46:56.4592922Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null,
              "parent_msg_id": "a6825a81-4468-4f51-a937-5034b8aaa6e8"
            },
            "text/plain": "StatementMeta(, , , Waiting, , Waiting)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "KeyboardInterrupt while sending command.\nTraceback (most recent call last):\n  File \"/home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n  File \"/home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1217, in send_command\n    answer = smart_decode(self.stream.readline()[:-1])\n  File \"/home/trusted-service-user/cluster-env/env/lib/python3.10/socket.py\", line 705, in readinto\n    return self._sock.recv_into(b)\nKeyboardInterrupt\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#PipelineModel.load(f\"{datastore}/models/ml_model_score_prediction\") \u001b[39;00m\n\u001b[1;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m RegressionEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_forest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot Mean Squared Error (RMSE) on test data = \u001b[39m\u001b[38;5;132;01m%g\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m rmse)\n",
            "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/ml/evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
            "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/ml/evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/cluster-env/env/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m~/cluster-env/env/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
            "File \u001b[0;32m~/cluster-env/env/lib/python3.10/site-packages/py4j/java_gateway.py:1217\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1218\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n",
            "File \u001b[0;32m~/cluster-env/env/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733794110543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job4_comments = spark(\n",
        "    description=\"states_averages\",\n",
        "    code=\"./\",\n",
        "    entry={\"file\": \"ml_forest_model.py\"},\n",
        "    driver_cores=1,\n",
        "    driver_memory=\"7g\",\n",
        "    executor_cores=4,\n",
        "    executor_memory=\"7g\",\n",
        "    executor_instances=6,\n",
        "    resources={\n",
        "        \"instance_type\": \"Standard_E4S_V3\",\n",
        "        \"runtime_version\": \"3.4\",\n",
        "    },\n",
        "    inputs={\n",
        "        \"input_data\": Input(\n",
        "            type=\"uri_folder\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/states/states_sentiment\",\n",
        "            mode=\"direct\",\n",
        "        ),\n",
        "    },\n",
        "    environment=\"sparknlp-python-env@latest\",\n",
        "    identity=UserIdentityConfiguration(),\n",
        "    args=\"--input_data ${{inputs.input_data}}\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_ml_object = azureml_client.jobs.create_or_update(job_ml_comments)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}